{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib \n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# world height\n",
    "WORLD_HEIGHT=7\n",
    "# world width\n",
    "WORLD_WIDTH=10\n",
    "# wind strenth for each column\n",
    "WIND=[0,0,0,1,1,1,2,2,1,0]\n",
    "#possible actions\n",
    "ACTION_UP=0\n",
    "ACTION_DOWN=1\n",
    "ACTION_LEFT=2\n",
    "ACTION_RIGHT=3\n",
    "#probability for exploration\n",
    "EPSILON=0.1\n",
    "#SARSA step size\n",
    "ALPHA=0.5\n",
    "# reward for each step\n",
    "REWARD=-1\n",
    "START=[3,0]\n",
    "GOAL=[3,7]\n",
    "ACTIONS=[ACTION_UP,ACTION_DOWN,ACTION_LEFT,ACTION_RIGHT]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def step(state,action):\n",
    "    i,j=state\n",
    "    if action == ACTION_UP:\n",
    "        return [max(i-1-WIND[j],0),j] #向上是-1，grid world最上面一行的纵坐标为0，最下面一行纵坐标为6，所以向上移动时选max（state，0），即state的纵坐标不能小于0\n",
    "    elif action == ACTION_DOWN:\n",
    "        return [max(min(i+1-WIND[j],WORLD_HEIGHT-1),0),j]#同理，向下移动时，state的纵坐标必须小于6，大于0\n",
    "    elif action == ACTION_LEFT:\n",
    "        return [max(i-WIND[j],0),max(j-1,0)]\n",
    "    elif action == ACTION_RIGHT:\n",
    "        return [max(i-WIND[j],0),min(j+1,WORLD_WIDTH-1)]\n",
    "    else:\n",
    "        assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# play an episode\n",
    "def episode(q_value):\n",
    "    #track the total time steps in this episode\n",
    "    time = 0\n",
    "    #initialize state\n",
    "    state = START\n",
    "    #choose an action based on epsilon-greedy algorithm\n",
    "    if np.random.binomial(1,EPSILON) == 1: #EPLISION > random(0,1)\n",
    "        action = np.random.choice(ACTIONS)\n",
    "    else:\n",
    "        values_ = q_value[state[0],state[1],:] #state[0]为横坐标，state[1]为纵坐标，：为actions；q_value[x,y]，x为state，y为actions\n",
    "        action = np.random.choice([action_ for action_, value_ in enumerate(values_) if value_ == np.max(values_)]) #enumerate是枚举，这里表示枚举出value_中的值及其序号，最后选取最大values_所对应的action\n",
    "    # keep going until get to the goal state\n",
    "    while state != GOAL:\n",
    "        next_state = step(state,action)\n",
    "        if np.random.binomial(1,EPSILON) == 1:\n",
    "            next_action = np.random.choice(ACTIONS)\n",
    "        else:\n",
    "            values_ = q_value[next_state[0],next_state[1],:]\n",
    "            next_action = np.random.choice([action_ for action_,value_ in enumerate(values_) if value_ == np.max(values_)])\n",
    "        #SARSA update\n",
    "        q_value[state[0],state[1],action] += ALPHA*(REWARD+q_value[next_state[0],next_state[1],next_action]-q_value[state[0],state[1],action])\n",
    "        state = next_state\n",
    "        action = next_action\n",
    "        time += 1\n",
    "    return time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sarsa():\n",
    "    q_value = np.zeros((WORLD_HEIGHT,WORLD_WIDTH,4)) #q_value初始值\n",
    "    episode_limit = 500\n",
    "    steps = []\n",
    "    ep = 0\n",
    "    while ep < episode_limit:\n",
    "        steps.append(episode(q_value))#将time存入steps\n",
    "        #time = episode(q_value)\n",
    "        #episode.extend([ep]*time)#将ep*time存入episode\n",
    "        ep += 1\n",
    "    steps = np.add.accumulate(steps) #累加序列\n",
    "    plt.plot(steps,np.arange(0,len(steps+1)))#np.arange(1,len(steps+1))生产1到len(steps)的数列\n",
    "    plt.xlabel('Time steps') \n",
    "    plt.ylabel('Episodes') \n",
    "    plt.savefig('./sarsa.png') \n",
    "    plt.close() \n",
    "    # display the optimal policy \n",
    "    optimal_policy = []\n",
    "    for i in range(0, WORLD_HEIGHT):\n",
    "        optimal_policy.append([])\n",
    "        for j in range(0, WORLD_WIDTH):\n",
    "            if [i, j] == GOAL:\n",
    "                optimal_policy[-1].append('G')#[-1]意思为在list末尾添加值\n",
    "                continue\n",
    "            bestAction = np.argmax(q_value[i, j, :])\n",
    "            if bestAction == ACTION_UP:\n",
    "                optimal_policy[-1].append('U')\n",
    "            elif bestAction == ACTION_DOWN:\n",
    "                optimal_policy[-1].append('D')\n",
    "            elif bestAction == ACTION_LEFT:\n",
    "                optimal_policy[-1].append('L')\n",
    "            elif bestAction == ACTION_RIGHT:\n",
    "                optimal_policy[-1].append('R')\n",
    "    print('Optimal policy is:')\n",
    "    for row in optimal_policy:\n",
    "        print(row)\n",
    "    print('Wind strength for each column:\\n{}'.format([str(w) for w in WIND]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal policy is:\n",
      "['R', 'D', 'L', 'R', 'R', 'R', 'R', 'R', 'R', 'D']\n",
      "['R', 'R', 'L', 'R', 'R', 'R', 'R', 'R', 'U', 'D']\n",
      "['R', 'R', 'R', 'R', 'R', 'R', 'R', 'U', 'R', 'D']\n",
      "['R', 'R', 'R', 'R', 'R', 'R', 'D', 'G', 'R', 'D']\n",
      "['R', 'D', 'D', 'R', 'R', 'R', 'U', 'D', 'L', 'D']\n",
      "['R', 'R', 'R', 'R', 'R', 'U', 'U', 'D', 'D', 'D']\n",
      "['R', 'R', 'R', 'R', 'U', 'U', 'U', 'U', 'U', 'L']\n",
      "Wind strength for each column:\n",
      "['0', '0', '0', '1', '1', '1', '2', '2', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__': \n",
    "    sarsa()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
